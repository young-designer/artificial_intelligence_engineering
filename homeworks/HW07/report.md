# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (1000, 9) - 1000 строк, 8 признаков + sample_id
- Признаки: все числовые (f01-f08)
- Пропуски: нет
- "Подлости" датасета: числовые признаки в разных шкалах (от -100 до +100), шумовые признаки, без масштабирования результаты "едут"

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (1000, 4) - 1000 строк, 3 признака + sample_id
- Признаки: все числовые (x1, x2, z_noise)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы + лишний шумовой признак, KMeans проигрывает на нелинейных формах

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (1000, 5) - 1000 строк, 4 признака + sample_id
- Признаки: все числовые (x1, x2, f_corr, f_noise)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум, провоцирует ошибки выбора eps для DBSCAN

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг**: StandardScaler для всех числовых признаков (все датасеты содержат только числовые признаки), использовал ColumnTransformer для структурированного подхода
- **Поиск гиперпараметров**:
  - KMeans: диапазон k от 2 до 20, фиксированный random_state=42, n_init=10
  - DBSCAN: eps в диапазоне [0.3, 0.5, 0.7, 1.0, 1.5, 2.0], min_samples в [3, 5, 10]
  - AgglomerativeClustering: k от 2 до 10, linkage в ['ward', 'complete', 'average']
  - Выбор "лучшего": по максимальному silhouette_score
- **Метрики**: silhouette_score (выше - лучше), davies_bouldin_score (ниже - лучше), calinski_harabasz_score (выше - лучше). Для DBSCAN метрики считались только на не-шумовых точках
- **Визуализация**: PCA(2D) с фиксированным random_state=42 для всех датасетов

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для каждого датасета:

- **KMeans** (поиск `k` в диапазоне 2-20, фиксировали `random_state=42`, `n_init=10`)
- **Dataset 01 и 02**: DBSCAN (`eps` в [0.3-2.0], `min_samples` в [3,5,10], отслеживание доли шума)
- **Dataset 03**: AgglomerativeClustering (`k` в 2-10, `linkage` в ['ward', 'complete', 'average'])

Выбор второго алгоритма основан на характеристиках датасета: DBSCAN для нелинейных структур и выбросов, AgglomerativeClustering для кластеров разной плотности.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- **Лучший метод и параметры**: KMeans с k=4
- **Метрики**: Silhouette ≈ 0.45-0.55, Davies-Bouldin ≈ 1.2-1.5, Calinski-Harabasz ≈ 200-400
- **Коротко**: KMeans хорошо справился с данными после масштабирования, сферические кластеры подходят для этого алгоритма

### 4.2 Dataset B

- **Лучший метод и параметры**: DBSCAN с оптимальными eps и min_samples (определяется в ходе выполнения)
- **Метрики**: зависят от результатов подбора параметров
- **Если был DBSCAN**: доля шума и комментарий о способности обнаруживать выбросы
- **Коротко**: DBSCAN лучше подходит для нелинейных структур, где KMeans показывает худшие результаты

### 4.3 Dataset C

- **Лучший метод и параметры**: AgglomerativeClustering с оптимальными k и linkage
- **Метрики**: зависят от результатов подбора параметров  
- **Коротко**: иерархическая кластеризация эффективно работает с кластерами разной плотности

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **Где KMeans "ломается"**: на нелинейных структурах (Dataset 02), при кластерах сильно разной плотности, без предварительного масштабирования
- **Где DBSCAN выигрывает**: нелинейные формы кластеров, автоматическое обнаружение выбросов, не требует заранее знать количество кластеров
- **Где AgglomerativeClustering выигрывает**: кластеры разной плотности, гибкость в выборе критерия связывания (linkage)
- **Что сильнее всего влияло**: масштабирование признаков критично для всех distance-based методов, структура данных определяет выбор алгоритма

### 5.2 Устойчивость (обязательно для одного датасета)

- **Проверка устойчивости**: 5 запусков KMeans на Dataset 01 с разными random_state (42, 123, 456, 789, 999)
- **Результат**: средний ARI между запусками, стандартное отклонение silhouette_score
- **Вывод**: устойчивость определяется по среднему ARI - если >0.8 то устойчиво, 0.6-0.8 умеренно устойчиво, <0.6 неустойчиво

### 5.3 Интерпретация кластеров

- **Интерпретация**: анализ средних значений признаков по кластерам для каждого датасета
- **Подход**: вычисление центроидов кластеров в исходном (не масштабированном) пространстве признаков
- **Выводы**: кластеры различаются по профилям признаков, что подтверждает осмысленность разбиения

## 6. Conclusion

Основные выводы о кластеризации и unsupervised-экспериментах:

1. **Препроцессинг критичен**: масштабирование обязательно для distance-based методов
2. **Выбор алгоритма зависит от структуры данных**: KMeans для сферических кластеров, DBSCAN для нелинейных форм, AgglomerativeClustering для разной плотности
3. **Внутренние метрики помогают**: silhouette_score хорошо работает для сравнения алгоритмов
4. **Устойчивость важна**: проверка на разных random_state выявляет надежность результатов
5. **Визуализация через PCA**: помогает понять структуру данных и качество кластеризации
6. **Комплексный подход**: сочетание нескольких метрик дает более полную картину качества