# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- **Какой датасет выбран:** `S06-hw-dataset-01.csv`
- **Размер:** (1200, 21) - 1200 строк, 21 столбец (включая id и target)
- **Целевая переменная:** `target` (бинарная классификация)
  - Класс 0: ~67.7%
  - Класс 1: ~32.3%
  - Умеренный дисбаланс классов
- **Признаки:** 19 числовых признаков, включая категориальные-подобные поля (целые значения с малой мощностью). Пропущенных значений нет.

## 2. Protocol

- **Разбиение:** train/test = 80%/20% (960/240), `random_state=42`
- **Стратификация:** применена для сохранения баланса классов
- **Подбор:** 5-fold CV на train, оптимизировали ROC-AUC
- **Метрики:** 
  - **Accuracy** - общая точность классификации
  - **F1-score** - гармоническое среднее precision и recall (важно при дисбалансе)
  - **ROC-AUC** - основная метрика, показывает качество ранжирования (устойчива к дисбалансу)

## 3. Models

Сравнивали следующие модели с подбором гиперпараметров:

**Baseline:**
- **DummyClassifier** (strategy='most_frequent') - минимальный baseline
- **LogisticRegression** с StandardScaler - линейный baseline

**Модели на деревьях:**
- **DecisionTreeClassifier** - контроль сложности через max_depth, min_samples_leaf, min_samples_split
- **RandomForestClassifier** - подбор n_estimators, max_depth, min_samples_leaf, max_features
- **GradientBoostingClassifier** - подбор n_estimators, learning_rate, max_depth, min_samples_leaf
- **StackingClassifier** - комбинация лучших моделей с LogisticRegression как метамодель

Все гиперпараметры подбирались через GridSearchCV с 5-fold CV на train.

## 4. Results

**Финальные метрики на test (отсортированы по ROC-AUC):**

| Model              | Accuracy | F1-score | ROC-AUC |
|--------------------|----------|----------|---------|
| GradientBoosting   | 0.9371   | 0.9002   | **0.9718** |
| Stacking           | 0.9400   | 0.9054   | 0.9705  |
| RandomForest       | 0.9292   | 0.8854   | 0.9673  |
| DecisionTree       | 0.8692   | 0.7942   | 0.9098  |
| LogisticRegression | 0.8275   | 0.7076   | 0.8747  |
| Dummy              | 0.6767   | 0.0000   | 0.0000  |

**Победитель:** GradientBoosting (ROC-AUC = 0.9718)

**Лучшие параметры:** learning_rate=0.2, max_depth=7, min_samples_leaf=10, n_estimators=150

**Объяснение:** Gradient Boosting показал лучший результат благодаря последовательному исправлению ошибок предыдущих моделей. Высокий learning_rate (0.2) и умеренная глубина (7) обеспечили хороший баланс между скоростью обучения и контролем переобучения.

## 5. Analysis

**Устойчивость:** При фиксированном random_state=42 результаты воспроизводимы. Все ансамбли показали стабильно высокое качество (ROC-AUC > 0.96), что говорит об устойчивости к случайным флуктуациям.

**Ошибки:** Confusion Matrix для GradientBoosting показывает отличное качество классификации с минимальным количеством ложных срабатываний. Модель хорошо разделяет оба класса.

**Интерпретация:** Permutation Importance для GradientBoosting выявил наиболее важные признаки для предсказания. Результаты показаны в графике `artifacts/figures/feature_importance.png`. Некоторые признаки имеют значительно большее влияние на качество предсказания, что указывает на их ключевую роль в задаче классификации.

## 6. Conclusion

1. **Ансамбли превосходят одиночные модели:** Random Forest, Gradient Boosting и Stacking показали ROC-AUC > 0.96, значительно превзойдя Decision Tree (0.91) и линейные модели (0.87).

2. **Контроль сложности критичен:** Decision Tree с ограничениями (min_samples_leaf=20) избежал переобучения и показал приемлемый результат, но уступил ансамблям.

3. **Gradient Boosting эффективен для табличных данных:** Последовательное исправление ошибок дало лучший результат среди всех моделей.

4. **Честный протокол обеспечивает надёжность:** Фиксированный train/test split, подбор параметров только на train через CV, и единократное использование test гарантируют объективную оценку.

5. **Stacking не всегда улучшает результат:** Несмотря на комбинирование сильных моделей, Stacking не превзошёл лучшую базовую модель, что показывает важность правильного выбора метамодели.

6. **Важность признаков помогает в интерпретации:** Permutation Importance выявил ключевые факторы, что важно для понимания предметной области и доверия к модели.