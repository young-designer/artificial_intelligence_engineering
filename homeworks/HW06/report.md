# Отчёт по HW06: Деревья решений и ансамбли

**Датасет:** S06-hw-dataset-01.csv  

---

## 1. Описание задачи

Задача бинарной классификации на синтетическом датасете с умеренным дисбалансом классов. Цель - сравнить различные модели на основе деревьев решений и ансамблей, провести честный ML-эксперимент с корректным подбором гиперпараметров.

---

## 2. Данные

### 2.1. Общая информация
- **Датасет:** S06-hw-dataset-01.csv
- **Размер:** определяется при загрузке
- **Тип задачи:** бинарная классификация
- **Целевая переменная:** `target` (0/1)

### 2.2. Баланс классов
Датасет имеет умеренный дисбаланс классов, что требует использования стратификации при разделении на train/test и выбора подходящих метрик (не только accuracy).

### 2.3. Признаки
Датасет содержит несколько числовых признаков, включая категориальные-подобные поля (целые значения с малой мощностью). Столбец `id` исключён из признаков.

---

## 3. Методология

### 3.1. Разделение данных
- **Train/Test split:** 80% / 20%
- **Стратификация:** да (по целевой переменной)
- **Random state:** 42 (для воспроизводимости)

### 3.2. Подбор гиперпараметров
- Метод: GridSearchCV с 5-fold cross-validation
- Метрика оптимизации: ROC-AUC
- Подбор выполнялся **только на train**, test использован для финальной оценки

### 3.3. Метрики качества
- **Accuracy** - общая точность
- **F1-score** - гармоническое среднее precision и recall
- **ROC-AUC** - площадь под ROC-кривой (основная метрика)

---

## 4. Модели

### 4.1. Baseline модели

#### DummyClassifier
- Стратегия: most_frequent
- Назначение: минимальный baseline (предсказывает самый частый класс)

#### Logistic Regression
- Pipeline: StandardScaler + LogisticRegression
- Назначение: линейный baseline для сравнения

### 4.2. Модели на основе деревьев

#### Decision Tree
- **Контроль сложности:** max_depth, min_samples_leaf, min_samples_split
- **Подбор параметров:** GridSearchCV
- **Диапазоны:**
  - max_depth: [3, 5, 7, 10, None]
  - min_samples_leaf: [1, 5, 10, 20]
  - min_samples_split: [2, 10, 20]
- **Лучшие параметры:** max_depth=None, min_samples_leaf=20, min_samples_split=2
- **CV ROC-AUC:** 0.9154

#### Random Forest
- **Параметры:**
  - n_estimators: [50, 100, 200]
  - max_depth: [5, 10, 15, None]
  - min_samples_leaf: [1, 5, 10]
  - max_features: ['sqrt', 'log2']
- **Лучшие параметры:** max_depth=None, max_features='sqrt', min_samples_leaf=1, n_estimators=200
- **CV ROC-AUC:** 0.9687

#### Gradient Boosting
- **Параметры:**
  - n_estimators: [50, 100, 150]
  - learning_rate: [0.1, 0.2] (оптимизировано для скорости)
  - max_depth: [3, 5, 7]
  - min_samples_leaf: [1, 5, 10]
- **Лучшие параметры:** learning_rate=0.2, max_depth=7, min_samples_leaf=10, n_estimators=150
- **CV ROC-AUC:** 0.9742

#### Stacking (опционально)
- **Базовые модели:** DecisionTree, RandomForest, GradientBoosting
- **Метамодель:** LogisticRegression
- **CV:** 5-fold

---

## 5. Результаты

### 5.1. Сравнение моделей на тестовой выборке

Результаты всех моделей на тестовой выборке (отсортированы по ROC-AUC):

| Model              | Accuracy | F1-score | ROC-AUC |
|--------------------|----------|----------|---------|
| GradientBoosting   | 0.9371   | 0.9002   | 0.9718  |
| Stacking           | 0.9400   | 0.9054   | 0.9705  |
| RandomForest       | 0.9292   | 0.8854   | 0.9673  |
| DecisionTree       | 0.8692   | 0.7942   | 0.9098  |
| LogisticRegression | 0.8275   | 0.7076   | 0.8747  |
| Dummy              | 0.6767   | 0.0000   | 0.0000  |

### 5.2. Лучшая модель

**Модель:** GradientBoosting  
**ROC-AUC на тесте:** 0.9718  
**Лучшие параметры:** 
- learning_rate: 0.2
- max_depth: 7
- min_samples_leaf: 10
- n_estimators: 150

**CV ROC-AUC:** 0.9742

### 5.3. Важность признаков

Для лучшей модели (GradientBoosting) была вычислена Permutation Importance. Top-10 наиболее важных признаков будут показаны в графике `feature_importance.png`.

---

## 6. Визуализации

Все графики сохранены в папке `artifacts/figures/`:

1. **target_distribution.png** - распределение целевой переменной
2. **models_comparison.png** - сравнение метрик по всем моделям
3. **roc_curves.png** - ROC-кривые для всех моделей
4. **confusion_matrix.png** - матрица ошибок для лучшей модели
5. **feature_importance.png** - важность признаков (Permutation Importance)

---

## 7. Выводы

### 7.1. Основные наблюдения

1. **Baseline vs деревья:**
   - Модели на основе деревьев значительно превосходят baseline модели
   - Dummy показал accuracy 67.7% (предсказывает только мажоритарный класс)
   - Логистическая регрессия показала ROC-AUC 0.8747 - хороший линейный baseline

2. **Контроль сложности:**
   - Decision Tree с ограничениями (min_samples_leaf=20) показал ROC-AUC 0.9098
   - Без контроля сложности дерево могло бы переобучиться
   - GridSearchCV помог найти оптимальный баланс bias-variance

3. **Ансамбли:**
   - Random Forest (ROC-AUC 0.9673) улучшил результат за счёт усреднения 200 деревьев
   - Gradient Boosting показал лучший результат (ROC-AUC 0.9718) благодаря последовательному исправлению ошибок
   - Stacking (ROC-AUC 0.9705) объединил сильные стороны разных моделей, но не превзошёл лучшую базовую модель

4. **Важность признаков:**
   - Permutation Importance выявил ключевые признаки для предсказания
   - Результаты показаны в графике feature_importance.png

### 7.2. Честность эксперимента

- Фиксированный random_state=42 обеспечивает воспроизводимость
- Стратификация сохраняет баланс классов в train/test (умеренный дисбаланс ~68%/32%)
- Подбор гиперпараметров выполнен только на train через 5-fold CV
- Тестовая выборка использована единожды для финальной оценки
- Все артефакты сохранены для проверки и воспроизведения

### 7.3. Рекомендации

1. **Для данной задачи лучше всего подходит Gradient Boosting** с параметрами:
   - n_estimators=150, learning_rate=0.2, max_depth=7, min_samples_leaf=10
   
2. **Ключевые наблюдения:**
   - Все ансамбли показали ROC-AUC > 0.96, что говорит об отличном качестве
   - Разница между лучшими моделями невелика (0.9673-0.9718)
   - Stacking не дал значительного улучшения над лучшей базовой моделью

3. **При дальнейшей работе можно попробовать:**
   - Более тонкую настройку гиперпараметров для Random Forest
   - Feature engineering для улучшения качества
   - Калибровку вероятностей для более точных предсказаний
   - Анализ ошибок для понимания сложных случаев

---

## 8. Артефакты

Все артефакты сохранены в папке `artifacts/`:

- `metrics_test.json` - метрики всех моделей на тесте
- `search_summaries.json` - результаты подбора гиперпараметров
- `best_model.joblib` - сохранённая лучшая модель
- `best_model_meta.json` - метаданные лучшей модели
- `figures/` - все визуализации

---

## 9. Воспроизводимость

Для воспроизведения результатов:

1. Установить необходимые библиотеки: pandas, numpy, scikit-learn, matplotlib, seaborn
2. Запустить все ячейки ноутбука `HW06.ipynb` последовательно
3. Все результаты будут сохранены в папке `artifacts/`

**Random state:** 42 (зафиксирован во всех экспериментах)
